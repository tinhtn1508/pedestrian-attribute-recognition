import os
import sys
from PIL import Image
import torch
import numpy as np
import torch.utils.data as data
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import pickle
import torch
import random

def gen_A(num_classes, t, adj_file):
    result = pickle.load(open(adj_file, 'rb'))
    _adj = result['adj']
    _nums = result['nums']
    _nums = _nums[:, np.newaxis]
    _adj = _adj / _nums
    _adj[_adj < t] = 0
    _adj[_adj >= t] = 1
    _adj = _adj * 0.25 / (_adj.sum(0, keepdims=True) + 1e-6)
    _adj = _adj + np.identity(num_classes, np.int)
    return _adj

def gen_adj(A):
    D = torch.pow(A.sum(1).float(), -0.5)
    D = torch.diag(D)
    adj = torch.matmul(torch.matmul(A, D).t(), D)
    return adj

def getDataInfo(path):
    with open(path, 'rb+') as f:
        dataset_info = pickle.load(f)
    return dataset_info

def default_loader(path):
    return Image.open(path).convert('RGB')

class MultiLabelDataset(data.Dataset):
    def __init__(self, split, dataset_info, transform=None, loader=default_loader, data_workspace=''):
        img_id = dataset_info.image_name
        attr_label = dataset_info.label
        self.transform = transform
        self.loader = loader
        self.root_path = dataset_info.root
        self.attr_id = dataset_info.attr_name
        self.attr_num = len(self.attr_id)
        self.img_idx = dataset_info.partition[split]
        self.img_num = self.img_idx.shape[0]
        self.img_id = [img_id[i] for i in self.img_idx]
        self.label = attr_label[self.img_idx]
        self.data_workspace = data_workspace

    def __getitem__(self, index):
        imgname, gt_label, _ = self.img_id[index], self.label[index], self.img_idx[index]
        imgpath = os.path.join(self.data_workspace, self.root_path, imgname)
        img = self.loader(imgpath)
        
        if self.transform is not None:
            img = self.transform(img)
        return img, torch.Tensor(gt_label), imgpath

    def getOriginImage(self, index):
        imgname, gt_label, _ = self.img_id[index], self.label[index], self.img_idx[index]
        imgpath = os.path.join(self.data_workspace, self.root_path, imgname)
        img = self.loader(imgpath)
        return img

    def __len__(self):
        return len(self.img_id)

    def toImageAttribute(self, attributeIndex):
        attr = []
        for attIndex, attName in zip(attributeIndex, self.attr_id):
            if attIndex == 1:
                attr.append(attName)
        return attr


def GetDataset(workspace, desciptionFile: str):
    data_info = getDataInfo(desciptionFile)
    train_dataset = MultiLabelDataset(split="train",
                    dataset_info=data_info, transform=None, data_workspace=workspace)
    test_dataset = MultiLabelDataset(split="test",
                    dataset_info=data_info, transform=None, data_workspace=workspace)
    return train_dataset, test_dataset, len(data_info.attr_name), data_info.attr_name, data_info.loss_weight

class MultiScaleCrop(object):

    def __init__(self, input_size, scales=None, max_distort=1, fix_crop=True, more_fix_crop=True):
        self.scales = scales if scales is not None else [1, 875, .75, .66]
        self.max_distort = max_distort
        self.fix_crop = fix_crop
        self.more_fix_crop = more_fix_crop
        self.input_size = input_size if not isinstance(input_size, int) else [input_size, input_size]
        self.interpolation = Image.BILINEAR

    def __call__(self, img):
        im_size = img.size
        crop_w, crop_h, offset_w, offset_h = self._sample_crop_size(im_size)
        crop_img_group = img.crop((offset_w, offset_h, offset_w + crop_w, offset_h + crop_h))
        ret_img_group = crop_img_group.resize((self.input_size[0], self.input_size[1]), self.interpolation)
        return ret_img_group

    def _sample_crop_size(self, im_size):
        image_w, image_h = im_size[0], im_size[1]

        # find a crop size
        base_size = min(image_w, image_h)
        crop_sizes = [int(base_size * x) for x in self.scales]
        crop_h = [self.input_size[1] if abs(x - self.input_size[1]) < 3 else x for x in crop_sizes]
        crop_w = [self.input_size[0] if abs(x - self.input_size[0]) < 3 else x for x in crop_sizes]

        pairs = []
        for i, h in enumerate(crop_h):
            for j, w in enumerate(crop_w):
                if abs(i - j) <= self.max_distort:
                    pairs.append((w, h))

        crop_pair = random.choice(pairs)
        if not self.fix_crop:
            w_offset = random.randint(0, image_w - crop_pair[0])
            h_offset = random.randint(0, image_h - crop_pair[1])
        else:
            w_offset, h_offset = self._sample_fix_offset(image_w, image_h, crop_pair[0], crop_pair[1])

        return crop_pair[0], crop_pair[1], w_offset, h_offset

    def _sample_fix_offset(self, image_w, image_h, crop_w, crop_h):
        offsets = self.fill_fix_offset(self.more_fix_crop, image_w, image_h, crop_w, crop_h)
        return random.choice(offsets)

    @staticmethod
    def fill_fix_offset(more_fix_crop, image_w, image_h, crop_w, crop_h):
        w_step = (image_w - crop_w) // 4
        h_step = (image_h - crop_h) // 4

        ret = list()
        ret.append((0, 0))  # upper left
        ret.append((4 * w_step, 0))  # upper right
        ret.append((0, 4 * h_step))  # lower left
        ret.append((4 * w_step, 4 * h_step))  # lower right
        ret.append((2 * w_step, 2 * h_step))  # center

        if more_fix_crop:
            ret.append((0, 2 * h_step))  # center left
            ret.append((4 * w_step, 2 * h_step))  # center right
            ret.append((2 * w_step, 4 * h_step))  # lower center
            ret.append((2 * w_step, 0 * h_step))  # upper center

            ret.append((1 * w_step, 1 * h_step))  # upper left quarter
            ret.append((3 * w_step, 1 * h_step))  # upper right quarter
            ret.append((1 * w_step, 3 * h_step))  # lower left quarter
            ret.append((3 * w_step, 3 * h_step))  # lower righ quarter
        return ret

    def __str__(self):
        return self.__class__.__name__
